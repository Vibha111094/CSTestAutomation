{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abstractive_Summarization_with_BERT_V2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vibha111094/CSTestAutomation/blob/master/Abstractive_Summarization_with_BERT_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pbgEu1oyhPca",
        "colab_type": "code",
        "outputId": "cdb04636-3f33-4d68-f83b-714656fa29f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LyrINzW1RVqU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf cnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UqeTD_eGkxVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R2rv402VOFFy",
        "colab_type": "code",
        "outputId": "789ab019-38f1-4b04-f480-649c7ada3c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "\n",
        "print(get_available_gpus())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/device:GPU:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SFCZikuuibh7",
        "colab_type": "code",
        "outputId": "71fbf636-5d05-4a3c-c9c5-88221984116c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!test -d texar_repo || git clone https://github.com/asyml/texar.git texar_repo\n",
        "if not 'texar_repo' in sys.path:\n",
        "  sys.path += ['texar_repo']\n",
        "!pip install funcsigs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: funcsigs in /usr/local/lib/python3.6/dist-packages (1.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OahAIQFOdB5l",
        "colab_type": "code",
        "outputId": "701818c3-90fd-4196-e199-538f55881c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "Rtl_-YvEcYdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -zxf cnn_stories.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3c6N-UcHGcJ4",
        "colab_type": "code",
        "outputId": "769f7c98-8553-41fa-ad62-229ae69b04f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Display punctuation.\n",
        "\n",
        "string_punctuation2=string.punctuation.replace('.', '')\n",
        "print(string_punctuation2)\n",
        "\n",
        "# for c in string.punctuation:\n",
        "#     string.punctuation2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-/:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_IB17muzsBd0",
        "colab_type": "code",
        "outputId": "e36f158f-a497-4f6e-a928-6d8d985a8c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# split a document into news story and highlights\n",
        "def split_story(doc):\n",
        "\t# find first highlight\n",
        "\tindex = doc.find('@highlight')\n",
        "\t# split into story and highlights\n",
        "\tstory, highlights = doc[:index], doc[index:].split('@highlight')\n",
        "\t# strip extra white space around each highlight\n",
        "\thighlights = [h.strip() for h in highlights if len(h) > 0]\n",
        "\treturn story, highlights\n",
        "\n",
        "# load all stories in a directory\n",
        "def load_stories(directory):\n",
        "\tstories = list()\n",
        "\tfor name in listdir(directory):\n",
        "\t\tfilename = directory + '/' + name\n",
        "\t\t# load document\n",
        "\t\tdoc = load_doc(filename)\n",
        "\t\t# split into story and highlights\n",
        "\t\tstory, highlights = split_story(doc)\n",
        "\t\t# store\n",
        "\t\tstories.append({'story':story, 'highlights':highlights})\n",
        "\treturn stories\n",
        "\n",
        "\n",
        "\n",
        "# def clean_lines(lines):\n",
        "# \tcleaned = list()\n",
        "# \t# prepare a translation table to remove punctuation\n",
        "# \ttable = str.maketrans('', '', string.punctuation)\n",
        "# \tfor line in lines:\n",
        "# \t\t# strip source cnn office if it exists\n",
        "# \t\tindex = line.find('(CNN) -- ')\n",
        "# \t\tif index > -1:\n",
        "# \t\t\tline = line[index+len('(CNN)'):]\n",
        "# \t\t# tokenize on white space\n",
        "# \t\t#line = line.split()\n",
        "# \t\t# convert to lower case\n",
        "# \t\t#line = [word.lower() for word in line]\n",
        "# \t\t# remove punctuation from each token\n",
        "# \t\t#line = [w.translate(table) for w in line]\n",
        "# \t\tline=line.lower()\n",
        "# \t\tline=nltk.word_tokenize(line)\n",
        "# \t\t# store as string\n",
        "# \t\tcleaned.append(' '.join(line))\n",
        "# \t# remove empty strings\n",
        "# \tcleaned = [c for c in cleaned if len(c) > 0]\n",
        "# \treturn cleaned\n",
        "#clean a list of lines\n",
        "\n",
        "def clean_lines(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare a translation table to remove punctuation\n",
        "\ttable = str.maketrans('', '', string_punctuation2)\n",
        "\tfor line in lines:\n",
        "\t\t# strip source cnn office if it exists\n",
        "\t\tindex = line.find('(CNN) -- ')\n",
        "\t\tif index > -1:\n",
        "\t\t\tline = line[index+len('(CNN)'):]\n",
        "\t\t# tokenize on white space\n",
        "\t\tline = line.split()\n",
        "\t\t# convert to lower case\n",
        "\t\tline = [word.lower() for word in line]\n",
        "\t\t# remove punctuation from each token\n",
        "\t\tline = [w.translate(table) for w in line]\n",
        "\t\t# remove tokens with numbers in them\n",
        "\t\t#line = [word for word in line if word.isalpha()]\n",
        "\t\t# store as string\n",
        "\t\tcleaned.append(' '.join(line))\n",
        "\t# remove empty strings\n",
        "\tcleaned = [c for c in cleaned if len(c) > 0]\n",
        "\treturn cleaned\n",
        "\n",
        "\n",
        "# load stories\n",
        "directory = 'cnn/stories/'\n",
        "stories = load_stories(directory)\n",
        "print('Loaded Stories %d' % len(stories))\n",
        "\n",
        "# clean stories\n",
        "f1 = open(\"stories.txt\",'w')\n",
        "f2 = open(\"summary.txt\",'w')\n",
        "for example in stories:\n",
        "  example['story'] = clean_lines(example['story'].split('\\n'))\n",
        "  example['highlights'] = clean_lines(example['highlights'])\n",
        "  for i in example['highlights']:\n",
        "    if(len(i)>399):\n",
        "        print(\"The length is\")\n",
        "        print(len(i))\n",
        "  f1.write(\" \".join(example['story']))\n",
        "  f1.write(\"\\n\")\n",
        "  f2.write(\" \".join(example['highlights']))\n",
        "  f2.write(\"\\n\")\n",
        "f1.close()\n",
        "f2.close()\n",
        "  \n",
        "story = open(\"stories.txt\").readlines()\n",
        "summ = open(\"summary.txt\").readlines() \n",
        "train_story = story[0:90000]\n",
        "train_summ = summ[0:90000]\n",
        "\n",
        "eval_story = story[90000:91579]\n",
        "eval_summ = summ[90000:91579]\n",
        "\n",
        "#print(eval_summ)\n",
        "\n",
        "\n",
        "test_story = story[91579:92579]\n",
        "test_summ = summ[91579:92579]\n",
        "\n",
        "\n",
        "with open(\"train_story.txt\",'w') as f:\n",
        "  f.write(\"\\n\".join(train_story))\n",
        "  \n",
        "with open(\"train_summ.txt\",'w') as f:\n",
        "  f.write(\"\\n\".join(train_summ))\n",
        "  \n",
        "with open(\"eval_story.txt\",'w') as f:\n",
        "  f.write(\"\\n\".join(eval_story))\n",
        "  \n",
        "  \n",
        "with open(\"eval_summ.txt\",'w') as f:\n",
        "  f.write(\"\\n\".join(eval_summ))\n",
        "  \n",
        "  \n",
        "with open(\"test_story.txt\",'w') as f:\n",
        "  f.write(\"\\n\".join(test_story))\n",
        "  \n",
        "  \n",
        "with open(\"test_summ.txt\",'w') as f:\n",
        "  f.write(\"\\n\".join(test_summ))  \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Loaded Stories 92579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YaWfqSGRZN8S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "0K7Tgn39LM82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SsWJmIfmij-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import collections\n",
        "import sys\n",
        "from texar_repo.examples.bert.utils import data_utils, model_utils, tokenization\n",
        "import importlib\n",
        "import tensorflow as tf\n",
        "import texar as tx \n",
        "from texar_repo.examples.bert import config_classifier as config_downstream\n",
        "from texar_repo.texar.utils import transformer_utils\n",
        "from texar_repo.examples.transformer.utils import data_utils, utils\n",
        "from texar_repo.examples.transformer.bleu_tool import bleu_wrapper\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ko2McfcdhbcN",
        "colab_type": "code",
        "outputId": "73f2c681-f15c-4f5f-f668-3f6be2b494ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#config\n",
        "\n",
        "dcoder_config = {\n",
        "    'dim': 768,\n",
        "    'num_blocks': 6,\n",
        "    'multihead_attention': {\n",
        "        'num_heads': 8,\n",
        "        'output_dim': 768\n",
        "        # See documentation for more optional hyperparameters\n",
        "    },\n",
        "    'position_embedder_hparams': {\n",
        "        'dim': 768\n",
        "    },\n",
        "    'initializer': {\n",
        "        'type': 'variance_scaling_initializer',\n",
        "        'kwargs': {\n",
        "            'scale': 1.0,\n",
        "            'mode': 'fan_avg',\n",
        "            'distribution': 'uniform',\n",
        "        },\n",
        "    },\n",
        "    'poswise_feedforward': tx.modules.default_transformer_poswise_net_hparams(\n",
        "        output_dim=768)\n",
        "}\n",
        "\n",
        "loss_label_confidence = 0.9\n",
        "\n",
        "random_seed = 1234\n",
        "beam_width = -1\n",
        "alpha = 0.6\n",
        "hidden_dim = 768\n",
        "\n",
        "\n",
        "opt = {\n",
        "    'optimizer': {\n",
        "        'type': 'AdamOptimizer',\n",
        "        'kwargs': {\n",
        "            'learning_rate':3e-4,\n",
        "            'beta1': 0.9,\n",
        "            'beta2': 0.997,\n",
        "            'epsilon': 1e-10\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "lr = {\n",
        "    'learning_rate_schedule': 'constant.linear_warmup.rsqrt_decay.rsqrt_depth',\n",
        "    'lr_constant': 2 * (hidden_dim ** -0.5),\n",
        "    'static_lr': 1e-3,\n",
        "    'warmup_steps': 2000,\n",
        "}\n",
        "\n",
        "bos_token_id =101\n",
        "eos_token_id = 102\n",
        "\n",
        "model_dir= \"./models\"\n",
        "run_mode= \"train_and_evaluate\"\n",
        "batch_size = 32\n",
        "test_batch_size = 32\n",
        "\n",
        "max_train_epoch = 20\n",
        "display_steps = 100\n",
        "eval_steps = 100000\n",
        "\n",
        "max_decoding_length = 400\n",
        "\n",
        "max_seq_length_src = 512\n",
        "max_seq_length_tgt = 400\n",
        "\n",
        "bert_pretrain_dir = 'bert_pretrained_models/uncased_L-12_H-768_A-12'\n",
        "print(bert_pretrain_dir)\n",
        "#config"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_pretrained_models/uncased_L-12_H-768_A-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WG1V_SfohZTl",
        "colab_type": "code",
        "outputId": "433ae9cf-ba08-4939-b69b-84be4edd60ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(opt.get('kwargs'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MrBw61rEiXeE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir bert_pretrained_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FH2RX773i40g",
        "colab_type": "code",
        "outputId": "b0e351d8-e955-46b0-cccb-1f6e9d6a5fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip -P bert_pretrained_models/;\n",
        "!unzip bert_pretrained_models/uncased_L-12_H-768_A-12.zip -d bert_pretrained_models/\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-06 07:53:29--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 209.85.200.128, 2607:f8b0:4001:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|209.85.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘bert_pretrained_models/uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   139MB/s    in 2.8s    \n",
            "\n",
            "2019-04-06 07:53:32 (139 MB/s) - ‘bert_pretrained_models/uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  bert_pretrained_models/uncased_L-12_H-768_A-12.zip\n",
            "   creating: bert_pretrained_models/uncased_L-12_H-768_A-12/\n",
            "  inflating: bert_pretrained_models/uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: bert_pretrained_models/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: bert_pretrained_models/uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: bert_pretrained_models/uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: bert_pretrained_models/uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JC60vOxGjI-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InputExample():\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence.\n",
        "                For single sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second\n",
        "                sequence. Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "                specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.src_txt = text_a\n",
        "        self.tgt_txt = text_b\n",
        "        \n",
        "class InputFeatures():\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, src_input_ids,src_input_mask,src_segment_ids,tgt_input_ids,tgt_input_mask,tgt_labels):\n",
        "        self.src_input_ids = src_input_ids\n",
        "        self.src_input_mask = src_input_mask\n",
        "        self.src_segment_ids = src_segment_ids\n",
        "        self.tgt_input_ids = tgt_input_ids\n",
        "        self.tgt_input_mask = tgt_input_mask \n",
        "        self.tgt_labels = tgt_labels\n",
        "        \n",
        "       \n",
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for prediction.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with tf.gfile.Open(input_file, \"r\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            i = 0\n",
        "            for line in reader:\n",
        "                lines.append(line)\n",
        "        return lines\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def _read_file(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with tf.gfile.Open(input_file, \"r\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\n\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            i = 0\n",
        "            for line in reader:\n",
        "                lines.append(line)\n",
        "        return lines\n",
        "      \n",
        "      \n",
        "class CNNDailymail(DataProcessor):\n",
        "    \"\"\"Processor for the CoLA data set (GLUE version).\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_file(os.path.join(data_dir, \"train_story.txt\")),self._read_file(os.path.join(data_dir, \"train_summ.txt\")),\n",
        "            \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_file(os.path.join(data_dir, \"eval_story.txt\")),self._read_file(os.path.join(data_dir, \"eval_summ.txt\")),\n",
        "            \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_file(os.path.join(data_dir, \"test_story.txt\")),self._read_file(os.path.join(data_dir, \"test_summ.txt\")),\n",
        "            \"test\")\n",
        "\n",
        "    def _create_examples(self, src_lines,tgt_lines,set_type):\n",
        "        examples = [] \n",
        "        for i,data in enumerate(zip(src_lines,tgt_lines)):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            if set_type == \"test\" and i == 0:\n",
        "                continue\n",
        "            else:\n",
        "                #print(data)\n",
        "                if len(data[0])==0 or len(data[1])==0:\n",
        "                  continue\n",
        "                src_lines = tokenization.convert_to_unicode(data[0][0])\n",
        "                tgt_lines = tokenization.convert_to_unicode(data[1][0])\n",
        "                examples.append(InputExample(guid=guid, text_a=src_lines,\n",
        "                                         text_b=tgt_lines))\n",
        "        return examples\n",
        "  \n",
        "  \n",
        "def file_based_convert_examples_to_features(\n",
        "        examples, max_seq_length_src,max_seq_length_tgt,tokenizer, output_file):\n",
        "    \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(output_file)\n",
        "    print(\"Vibha\")\n",
        "\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        #print(\"ex_index\",ex_index)\n",
        "\n",
        "        if (ex_index+1) %1000 == 0 :\n",
        "          print(\"------------processed..{}...examples\".format(ex_index))\n",
        "          \n",
        "        feature = convert_single_example(ex_index, example,\n",
        "                                         max_seq_length_src,max_seq_length_tgt,tokenizer)\n",
        "\n",
        "        def create_int_feature(values):\n",
        "            return tf.train.Feature(\n",
        "                int64_list=tf.train.Int64List(value=list(values)))\n",
        "\n",
        "        features = collections.OrderedDict()\n",
        "        features[\"src_input_ids\"] = create_int_feature(feature.src_input_ids)\n",
        "        features[\"src_input_mask\"] = create_int_feature(feature.src_input_mask)\n",
        "        features[\"src_segment_ids\"] = create_int_feature(feature.src_segment_ids)\n",
        "\n",
        "        features[\"tgt_input_ids\"] = create_int_feature(feature.tgt_input_ids)\n",
        "        features[\"tgt_input_mask\"] = create_int_feature(feature.tgt_input_mask)\n",
        "        features['tgt_labels'] = create_int_feature(feature.tgt_labels)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #print(feature.tgt_labels)\n",
        "        \n",
        "\n",
        "        tf_example = tf.train.Example(\n",
        "            features=tf.train.Features(feature=features))\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "\n",
        "def convert_single_example(ex_index, example, max_seq_length_src,max_seq_length_tgt,\n",
        "                           tokenizer):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "    \"\"\"\n",
        "    label_map = {}\n",
        "    for (i, label) in enumerate(label_list):\n",
        "        label_map[label] = i\n",
        "    \"\"\"\n",
        "#    print(example)\n",
        "#     tokens_a = tokenizer.tokenize(example['src_txt'])\n",
        "#     tokens_b = tokenizer.tokenize(example['tgt_txt'])\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.src_txt)\n",
        "    tokens_b = tokenizer.tokenize(example.tgt_txt)\n",
        "    \n",
        "\n",
        "\n",
        "    # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "    # length is less than the specified length.\n",
        "    # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "    if len(tokens_a) > max_seq_length_src - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length_src - 2)]\n",
        "    \n",
        "    if len(tokens_b) > max_seq_length_tgt - 2:\n",
        "            tokens_b = tokens_b[0:(max_seq_length_tgt - 2)]\n",
        "    #print(\"yay\")\n",
        "\n",
        "    \n",
        "    tokens_src = []\n",
        "    segment_ids_src = []\n",
        "    tokens_src.append(\"[CLS]\")\n",
        "    segment_ids_src.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens_src.append(token)\n",
        "        segment_ids_src.append(0)\n",
        "    tokens_src.append(\"[SEP]\")\n",
        "    segment_ids_src.append(0)\n",
        "  \n",
        "\n",
        "    tokens_tgt = []\n",
        "    segment_ids_tgt = []\n",
        "    tokens_tgt.append(\"[CLS]\")\n",
        "    #segment_ids_tgt.append(0)\n",
        "    for token in tokens_b:\n",
        "        tokens_tgt.append(token)\n",
        "        #segment_ids_tgt.append(0)\n",
        "    tokens_tgt.append(\"[SEP]\")\n",
        "    #segment_ids_tgt.append(0)\n",
        "\n",
        "    input_ids_src = tokenizer.convert_tokens_to_ids(tokens_src)\n",
        "   \n",
        "    \n",
        "\n",
        "    input_ids_tgt = tokenizer.convert_tokens_to_ids(tokens_tgt)\n",
        "    \n",
        "    #Adding begiining and end token\n",
        "    input_ids_tgt = input_ids_tgt[:-1] \n",
        "    \n",
        "    input_mask_src = [1] * len(input_ids_src)\n",
        "\n",
        "\n",
        "    input_mask_tgt = [1] * len(input_ids_tgt)\n",
        "    \n",
        "    labels_tgt = input_ids_tgt[1:]\n",
        "    \n",
        "    \n",
        "    labels_tgt.append(0)\n",
        "    \n",
        "    #print(len(input_ids_tgt))\n",
        "    #print(len(input_mask_tgt))\n",
        "    #print(len(labels_tgt))\n",
        "    #print(len(segment_ids_tgt))\n",
        "    \n",
        "    while len(input_ids_src) < max_seq_length_src:\n",
        "        input_ids_src.append(0)\n",
        "        input_mask_src.append(0)\n",
        "        segment_ids_src.append(0)\n",
        "\n",
        "    while len(input_ids_tgt) < max_seq_length_tgt:\n",
        "        input_ids_tgt.append(0)\n",
        "        input_mask_tgt.append(0)\n",
        "        segment_ids_tgt.append(0)\n",
        "        labels_tgt.append(0)\n",
        "    \n",
        "\n",
        "    feature = InputFeatures( src_input_ids=input_ids_src,src_input_mask=input_mask_src,src_segment_ids=segment_ids_src,\n",
        "        tgt_input_ids=input_ids_tgt,tgt_input_mask=input_mask_tgt,tgt_labels=labels_tgt)\n",
        "\n",
        "    \n",
        "    return feature\n",
        "\n",
        "\n",
        "def file_based_input_fn_builder(input_file, max_seq_length_src,max_seq_length_tgt, is_training,\n",
        "                                drop_remainder, is_distributed=False):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "    name_to_features = {\n",
        "        \"src_input_ids\": tf.FixedLenFeature([max_seq_length_src], tf.int64),\n",
        "        \"src_input_mask\": tf.FixedLenFeature([max_seq_length_src], tf.int64),\n",
        "        \"src_segment_ids\": tf.FixedLenFeature([max_seq_length_src], tf.int64),\n",
        "        \"tgt_input_ids\": tf.FixedLenFeature([max_seq_length_tgt], tf.int64),\n",
        "        \"tgt_input_mask\": tf.FixedLenFeature([max_seq_length_tgt], tf.int64),\n",
        "        \"tgt_labels\" : tf.FixedLenFeature([max_seq_length_tgt], tf.int64),\n",
        "        \n",
        "        \n",
        "    }\n",
        "\n",
        "    def _decode_record(record, name_to_features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.parse_single_example(record, name_to_features)\n",
        "        print(example)\n",
        "        print(example.keys())\n",
        "\n",
        "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "        # So cast all int64 to int32.\n",
        "        for name in list(example.keys()):\n",
        "            t = example[name]\n",
        "            if t.dtype == tf.int64:\n",
        "                t = tf.to_int32(t)\n",
        "            example[name] = t\n",
        "\n",
        "        return example\n",
        "\n",
        "    def input_fn(params):\n",
        "        \"\"\"The actual input function.\"\"\"\n",
        "        batch_size = params[\"batch_size\"]\n",
        "\n",
        "        # For training, we want a lot of parallel reading and shuffling.\n",
        "        # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "        d = tf.data.TFRecordDataset(input_file)\n",
        "        if is_training:\n",
        "\n",
        "            if is_distributed:\n",
        "                import horovod.tensorflow as hvd\n",
        "                tf.logging.info('distributed mode is enabled.'\n",
        "                                'size:{} rank:{}'.format(hvd.size(), hvd.rank()))\n",
        "                # https://github.com/uber/horovod/issues/223\n",
        "                d = d.shard(hvd.size(), hvd.rank())\n",
        "\n",
        "                d = d.repeat()\n",
        "                d = d.shuffle(buffer_size=100)\n",
        "                d = d.apply(\n",
        "                    tf.contrib.data.map_and_batch(\n",
        "                        lambda record: _decode_record(record, name_to_features),\n",
        "                        batch_size=batch_size//hvd.size(),\n",
        "                        drop_remainder=drop_remainder))\n",
        "            else:\n",
        "                tf.logging.info('distributed mode is not enabled.')\n",
        "                d = d.repeat()\n",
        "                d = d.shuffle(buffer_size=100)\n",
        "                d = d.apply(\n",
        "                    tf.contrib.data.map_and_batch(\n",
        "                        lambda record: _decode_record(record, name_to_features),\n",
        "                        batch_size=batch_size,\n",
        "                        drop_remainder=drop_remainder))\n",
        "\n",
        "        else:\n",
        "            d = d.apply(\n",
        "                tf.contrib.data.map_and_batch(\n",
        "                    lambda record: _decode_record(record, name_to_features),\n",
        "                    batch_size=batch_size,\n",
        "                    drop_remainder=drop_remainder))\n",
        "\n",
        "        return d\n",
        "    return input_fn\n",
        "  \n",
        "  \n",
        "def get_dataset(processor,\n",
        "                tokenizer,\n",
        "                data_dir,\n",
        "                max_seq_length_src,\n",
        "                max_seq_length_tgt,\n",
        "                batch_size,\n",
        "                mode,\n",
        "                output_dir,\n",
        "                is_distributed=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        processor: Data Preprocessor, must have get_lables,\n",
        "            get_train/dev/test/examples methods defined.\n",
        "        tokenizer: The Sentence Tokenizer. Generally should be\n",
        "            SentencePiece Model.\n",
        "        data_dir: The input data directory.\n",
        "        max_seq_length: Max sequence length.\n",
        "        batch_size: mini-batch size.\n",
        "        model: `train`, `eval` or `test`.\n",
        "        output_dir: The directory to save the TFRecords in.\n",
        "    \"\"\"\n",
        "    #label_list = processor.get_labels()\n",
        "    if mode == 'train':\n",
        "        #train_examples = processor.get_train_examples(data_dir)\n",
        "        #train_file = os.path.join(output_dir, \"train.tf_record\")\n",
        "        train_file = \"gs://my_bert_summ/train2.tf_record\"\n",
        "        #file_based_convert_examples_to_features(\n",
        "        #    train_examples, max_seq_length_src,max_seq_length_tgt,\n",
        "        #    tokenizer, train_file)\n",
        "        dataset = file_based_input_fn_builder(\n",
        "            input_file=train_file,\n",
        "            max_seq_length_src=max_seq_length_src,\n",
        "            max_seq_length_tgt =max_seq_length_tgt,\n",
        "            is_training=True,\n",
        "            drop_remainder=True,\n",
        "            is_distributed=is_distributed)({'batch_size': batch_size})\n",
        "    elif mode == 'eval':\n",
        "        #eval_examples = processor.get_dev_examples(data_dir)\n",
        "        #eval_file = os.path.join(output_dir, \"eval.tf_record\")\n",
        "        eval_file = \"gs://my_bert_summ/eval2.tf_record\"\n",
        "        #file_based_convert_examples_to_features(\n",
        "        #    eval_examples, max_seq_length_src,max_seq_length_tgt,\n",
        "        #    tokenizer, eval_file)\n",
        "        dataset = file_based_input_fn_builder(\n",
        "            input_file=eval_file,\n",
        "            max_seq_length_src=max_seq_length_src,\n",
        "            max_seq_length_tgt =max_seq_length_tgt,\n",
        "            is_training=False,\n",
        "            drop_remainder=True,\n",
        "            is_distributed=is_distributed)({'batch_size': batch_size})\n",
        "    elif mode == 'test':\n",
        "      \n",
        "        #test_examples = processor.get_test_examples(data_dir)\n",
        "        #test_file = os.path.join(output_dir, \"predict.tf_record\")\n",
        "        test_file = \"gs://my_bert_summ/predict2.tf_record\"\n",
        "        \n",
        "        #file_based_convert_examples_to_features(\n",
        "        #    test_examples, max_seq_length_src,max_seq_length_tgt,\n",
        "        #    tokenizer, test_file)\n",
        "        dataset = file_based_input_fn_builder(\n",
        "            input_file=test_file,\n",
        "            max_seq_length_src=max_seq_length_src,\n",
        "            max_seq_length_tgt =max_seq_length_tgt,\n",
        "            is_training=False,\n",
        "            drop_remainder=True,\n",
        "            is_distributed=is_distributed)({'batch_size': batch_size})\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upwxCtlDmAhC",
        "colab_type": "code",
        "outputId": "0daae6f3-85d5-42e6-ddaa-3c75b2ff2675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(alpha)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nn4vhTvJjT0D",
        "colab_type": "code",
        "outputId": "60988d83-a997-4b8c-c49d-8e43d9d37a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1251
        }
      },
      "cell_type": "code",
      "source": [
        "bert_config = model_utils.transform_bert_to_texar_config(\n",
        "            os.path.join(bert_pretrain_dir, 'bert_config.json'))\n",
        "print(bert_config)\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "        vocab_file=os.path.join(bert_pretrain_dir, 'vocab.txt'),\n",
        "        do_lower_case=True)\n",
        "\n",
        "vocab_size = len(tokenizer.vocab)\n",
        "\n",
        "processor = CNNDailymail()\n",
        "train_dataset = get_dataset(processor,tokenizer,\"./\",max_seq_length_src,max_seq_length_tgt,4,'train',\"./\")\n",
        "eval_dataset = get_dataset(processor,tokenizer,\"./\",max_seq_length_src,max_seq_length_tgt,4,'eval',\"./\")\n",
        "test_dataset = get_dataset(processor,tokenizer,\"./\",max_seq_length_src,max_seq_length_tgt,4,'test',\"./\")\n",
        "#del processor"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"embed\": {\n",
            "    \"dim\": 768,\n",
            "    \"name\": \"word_embeddings\"\n",
            "  },\n",
            "  \"encoder\": {\n",
            "    \"dim\": 768,\n",
            "    \"embedding_dropout\": 0.1,\n",
            "    \"multihead_attention\": {\n",
            "      \"dropout_rate\": 0.1,\n",
            "      \"name\": \"self\",\n",
            "      \"num_heads\": 12,\n",
            "      \"num_units\": 768,\n",
            "      \"output_dim\": 768,\n",
            "      \"use_bias\": true\n",
            "    },\n",
            "    \"name\": \"encoder\",\n",
            "    \"num_blocks\": 12,\n",
            "    \"position_embedder_hparams\": {\n",
            "      \"dim\": 768\n",
            "    },\n",
            "    \"position_embedder_type\": \"variables\",\n",
            "    \"position_size\": 512,\n",
            "    \"poswise_feedforward\": {\n",
            "      \"layers\": [\n",
            "        {\n",
            "          \"kwargs\": {\n",
            "            \"activation\": \"gelu\",\n",
            "            \"name\": \"intermediate\",\n",
            "            \"units\": 3072,\n",
            "            \"use_bias\": true\n",
            "          },\n",
            "          \"type\": \"Dense\"\n",
            "        },\n",
            "        {\n",
            "          \"kwargs\": {\n",
            "            \"activation\": null,\n",
            "            \"name\": \"output\",\n",
            "            \"units\": 768,\n",
            "            \"use_bias\": true\n",
            "          },\n",
            "          \"type\": \"Dense\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"residual_dropout\": 0.1,\n",
            "    \"use_bert_config\": true\n",
            "  },\n",
            "  \"hidden_size\": 768,\n",
            "  \"random_seed\": 123,\n",
            "  \"segment_embed\": {\n",
            "    \"dim\": 768,\n",
            "    \"name\": \"token_type_embeddings\"\n",
            "  },\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "INFO:tensorflow:distributed mode is not enabled.\n",
            "WARNING:tensorflow:From <ipython-input-5-86606632d85c>:305: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "{'src_input_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:0' shape=(512,) dtype=int64>, 'src_input_mask': <tf.Tensor 'ParseSingleExample/ParseSingleExample:1' shape=(512,) dtype=int64>, 'src_segment_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:2' shape=(512,) dtype=int64>, 'tgt_input_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:3' shape=(400,) dtype=int64>, 'tgt_input_mask': <tf.Tensor 'ParseSingleExample/ParseSingleExample:4' shape=(400,) dtype=int64>, 'tgt_labels': <tf.Tensor 'ParseSingleExample/ParseSingleExample:5' shape=(400,) dtype=int64>}\n",
            "dict_keys(['src_input_ids', 'src_input_mask', 'src_segment_ids', 'tgt_input_ids', 'tgt_input_mask', 'tgt_labels'])\n",
            "WARNING:tensorflow:From <ipython-input-5-86606632d85c>:269: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "{'src_input_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:0' shape=(512,) dtype=int64>, 'src_input_mask': <tf.Tensor 'ParseSingleExample/ParseSingleExample:1' shape=(512,) dtype=int64>, 'src_segment_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:2' shape=(512,) dtype=int64>, 'tgt_input_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:3' shape=(400,) dtype=int64>, 'tgt_input_mask': <tf.Tensor 'ParseSingleExample/ParseSingleExample:4' shape=(400,) dtype=int64>, 'tgt_labels': <tf.Tensor 'ParseSingleExample/ParseSingleExample:5' shape=(400,) dtype=int64>}\n",
            "dict_keys(['src_input_ids', 'src_input_mask', 'src_segment_ids', 'tgt_input_ids', 'tgt_input_mask', 'tgt_labels'])\n",
            "{'src_input_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:0' shape=(512,) dtype=int64>, 'src_input_mask': <tf.Tensor 'ParseSingleExample/ParseSingleExample:1' shape=(512,) dtype=int64>, 'src_segment_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:2' shape=(512,) dtype=int64>, 'tgt_input_ids': <tf.Tensor 'ParseSingleExample/ParseSingleExample:3' shape=(400,) dtype=int64>, 'tgt_input_mask': <tf.Tensor 'ParseSingleExample/ParseSingleExample:4' shape=(400,) dtype=int64>, 'tgt_labels': <tf.Tensor 'ParseSingleExample/ParseSingleExample:5' shape=(400,) dtype=int64>}\n",
            "dict_keys(['src_input_ids', 'src_input_mask', 'src_segment_ids', 'tgt_input_ids', 'tgt_input_mask', 'tgt_labels'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AHTu3UA4VvYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.size(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDhy0XGlIcY2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del processor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CBXxrBteAuVj",
        "colab_type": "code",
        "outputId": "6eefbd26-5532-4450-d27c-643c5292ba50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "lfw2JV11jsad",
        "colab_type": "code",
        "outputId": "59629a20-82a7-45e3-a0a4-7270ef32424f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "#inputs to the model\n",
        "src_input_ids = tf.placeholder(tf.int64, shape=(None, None))\n",
        "src_segment_ids = tf.placeholder(tf.int64, shape=(None, None))\n",
        "tgt_input_ids = tf.placeholder(tf.int64, shape=(None, None))\n",
        "tgt_segment_ids = tf.placeholder(tf.int64, shape=(None, None))\n",
        "\n",
        "batch_size = tf.shape(src_input_ids)[0]\n",
        "\n",
        "src_input_length = tf.reduce_sum(1 - tf.to_int32(tf.equal(src_input_ids, 0)),\n",
        "                             axis=1)\n",
        "tgt_input_length = tf.reduce_sum(1 - tf.to_int32(tf.equal(src_input_ids, 0)),\n",
        "                             axis=1)\n",
        "\n",
        "labels = tf.placeholder(tf.int64, shape=(None, None))\n",
        "is_target = tf.to_float(tf.not_equal(labels, 0))\n",
        "\n",
        "\n",
        "global_step = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
        "learning_rate = tf.placeholder(tf.float64, shape=(), name='lr')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-54824d78f153>:14: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jTFde06_kACm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create the iterator \n",
        "iterator = tx.data.FeedableDataIterator({\n",
        "        'train': train_dataset, 'eval': eval_dataset, 'test': test_dataset})\n",
        "\n",
        "batch = iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSrDO5YBkPYh",
        "colab_type": "code",
        "outputId": "124adcf3-47eb-4810-af9e-e914b3fcac41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "#encoder Bert model\n",
        "print(\"Intializing the Bert Encoder Graph\")\n",
        "with tf.variable_scope('bert'):\n",
        "        embedder = tx.modules.WordEmbedder(\n",
        "            vocab_size=bert_config.vocab_size,\n",
        "            hparams=bert_config.embed)\n",
        "        word_embeds = embedder(src_input_ids)\n",
        "\n",
        "        # Creates segment embeddings for each type of tokens.\n",
        "        segment_embedder = tx.modules.WordEmbedder(\n",
        "            vocab_size=bert_config.type_vocab_size,\n",
        "            hparams=bert_config.segment_embed)\n",
        "        segment_embeds = segment_embedder(src_segment_ids)\n",
        "\n",
        "        input_embeds = word_embeds + segment_embeds\n",
        "\n",
        "        # The BERT model (a TransformerEncoder)\n",
        "        #bert_config.encoder=tf.stop_gradient(bert_config.encoder)\n",
        "        encoder = tx.modules.TransformerEncoder(hparams=bert_config.encoder)\n",
        "        encoder_output = encoder(input_embeds, src_input_length)\n",
        "        \n",
        "        # Builds layers for downstream classification, which is also initialized\n",
        "        # with BERT pre-trained checkpoint.\n",
        "        with tf.variable_scope(\"pooler\"):\n",
        "            # Uses the projection of the 1st-step hidden vector of BERT output\n",
        "            # as the representation of the sentence\n",
        "            bert_sent_hidden = tf.squeeze(encoder_output[:, 0:1, :], axis=1)\n",
        "            bert_sent_output = tf.layers.dense(\n",
        "                bert_sent_hidden, config_downstream.hidden_dim,\n",
        "                activation=tf.tanh)\n",
        "            output = tf.layers.dropout(\n",
        "                bert_sent_output, rate=0.1, training=tx.global_mode_train())\n",
        "\n",
        "\n",
        "print(\"loading the bert pretrained weights\")\n",
        "# Loads pretrained BERT model parameters\n",
        "init_checkpoint = os.path.join(bert_pretrain_dir, 'bert_model.ckpt')\n",
        "init_checkpoint = \"gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "model_utils.init_bert_checkpoint(init_checkpoint)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intializing the Bert Encoder Graph\n",
            "WARNING:tensorflow:From texar_repo/texar/modules/encoders/transformer_encoders.py:340: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From <ipython-input-9-5636ab429ebb>:29: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "loading the bert pretrained weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WUnQ82OacbWW",
        "colab_type": "code",
        "outputId": "f8a64e73-fbff-4766-b849-5c2b9fdec431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "bert_config.encoder"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<texar.hyperparams.HParams at 0x7ffadc014828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "B0pBEmlh15NF",
        "colab_type": "code",
        "outputId": "11e3f03e-ef7a-434a-ef8c-31bbcca388e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "type(encoder_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "5faSZK-erGcs",
        "colab_type": "code",
        "outputId": "25ffee43-b7ed-4f98-d129-e9d30d8b7da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bert/encoder_1/layer_11/ffn/LayerNorm/batchnorm/add_1:0' shape=(?, ?, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "FJWb270X7avZ",
        "colab_type": "code",
        "outputId": "38a83f07-2a42-46ca-8b12-37a8d9218cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "bert_sent_hidden"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bert/pooler/Squeeze:0' shape=(?, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "2in1EYD6-xRA",
        "colab_type": "code",
        "outputId": "b76a7878-372e-4a55-91aa-63533e6d1de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "bert_sent_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bert/pooler/dense/Tanh:0' shape=(?, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "zyXQhl41_AqQ",
        "colab_type": "code",
        "outputId": "72a4bdea-3d44-4b54-8f16-7eff8c1f2cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bert/pooler/dropout/cond/Merge:0' shape=(?, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "C5m48bu5kVXm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#decoder part and mle losss\n",
        "tgt_embedding = tf.concat(\n",
        "    [tf.zeros(shape=[1, embedder.dim]), embedder.embedding[1:, :]], axis=0)\n",
        "\n",
        "decoder = tx.modules.TransformerDecoder(embedding=tgt_embedding,\n",
        "                             hparams=dcoder_config)\n",
        "# For training\n",
        "outputs = decoder(\n",
        "    memory=encoder_output,\n",
        "    memory_sequence_length=src_input_length,\n",
        "    inputs=embedder(tgt_input_ids),\n",
        "    sequence_length=tgt_input_length,\n",
        "    decoding_strategy='train_greedy',\n",
        "    mode=tf.estimator.ModeKeys.TRAIN\n",
        ")\n",
        "#print(\"output of the logits is\")\n",
        "#print(outputs.logits)\n",
        "#output_word = tf.nn.softmax(outputs.logits)\n",
        "# with tf.Session() as sess:\n",
        "#     print(\"Yay!!Lion\")\n",
        "#     c=sess.run(output_word)\n",
        "#     print(c)\n",
        "#     sess.close()\n",
        "mle_loss = transformer_utils.smoothing_cross_entropy(\n",
        "        outputs.logits, labels, vocab_size, loss_label_confidence)\n",
        "mle_loss = tf.reduce_sum(mle_loss * is_target) / tf.reduce_sum(is_target)\n",
        "\n",
        "allvars = []\n",
        "#print(len(allvars))\n",
        "allvars = tf.contrib.framework.get_trainable_variables()\n",
        "# print(allvars)\n",
        "nonBert=[]\n",
        "for v in allvars:\n",
        "    v1=str(v)\n",
        "    if \"bert\" not in v1:\n",
        "        nonBert.append(v)\n",
        "tvars =tf.trainable_variables()\n",
        "non_bert_vars = [var for var in tvars if 'bert' not in var.name]\n",
        "\n",
        "#print(\"nonBert is\")        \n",
        "#print(tvars)\n",
        "    \n",
        "train_op = tx.core.get_train_op(\n",
        "mle_loss,\n",
        "learning_rate=learning_rate,\n",
        "variables=non_bert_vars,\n",
        "global_step=global_step,\n",
        "hparams=opt)\n",
        "\n",
        "\n",
        "\n",
        "tf.summary.scalar('lr', learning_rate)\n",
        "tf.summary.scalar('mle_loss', mle_loss)\n",
        "summary_merged = tf.summary.merge_all()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Mk2n0FlbYLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt.get()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3xdNUOi1cZE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5W6zxzz25k0",
        "colab_type": "code",
        "outputId": "0b0efde3-824f-421f-d9dc-8e3eb79348f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "print(non_bert_vars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'transformer_decoder/layer_0/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/self_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/self_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/self_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/self_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/encdec_attention/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/encdec_attention/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/encdec_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/encdec_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/encdec_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/encdec_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/past_poswise_ln/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/past_poswise_ln/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/ffn/conv1/kernel:0' shape=(768, 3072) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/ffn/conv1/bias:0' shape=(3072,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/ffn/conv2/kernel:0' shape=(3072, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_0/ffn/conv2/bias:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/self_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/self_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/self_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/self_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/encdec_attention/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/encdec_attention/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/encdec_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/encdec_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/encdec_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/encdec_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/past_poswise_ln/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/past_poswise_ln/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/ffn/conv1/kernel:0' shape=(768, 3072) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/ffn/conv1/bias:0' shape=(3072,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/ffn/conv2/kernel:0' shape=(3072, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_1/ffn/conv2/bias:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/self_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/self_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/self_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/self_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/encdec_attention/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/encdec_attention/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/encdec_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/encdec_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/encdec_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/encdec_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/past_poswise_ln/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/past_poswise_ln/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/ffn/conv1/kernel:0' shape=(768, 3072) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/ffn/conv1/bias:0' shape=(3072,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/ffn/conv2/kernel:0' shape=(3072, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_2/ffn/conv2/bias:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/self_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/self_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/self_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/self_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/encdec_attention/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/encdec_attention/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/encdec_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/encdec_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/encdec_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/encdec_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/past_poswise_ln/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/past_poswise_ln/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/ffn/conv1/kernel:0' shape=(768, 3072) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/ffn/conv1/bias:0' shape=(3072,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/ffn/conv2/kernel:0' shape=(3072, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_3/ffn/conv2/bias:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/self_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/self_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/self_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/self_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/encdec_attention/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/encdec_attention/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/encdec_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/encdec_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/encdec_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/encdec_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/past_poswise_ln/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/past_poswise_ln/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/ffn/conv1/kernel:0' shape=(768, 3072) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/ffn/conv1/bias:0' shape=(3072,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/ffn/conv2/kernel:0' shape=(3072, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_4/ffn/conv2/bias:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/self_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/self_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/self_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/self_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/encdec_attention/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/encdec_attention/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/encdec_attention/multihead_attention/query/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/encdec_attention/multihead_attention/key/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/encdec_attention/multihead_attention/value/kernel:0' shape=(768, 512) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/encdec_attention/multihead_attention/output/kernel:0' shape=(512, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/past_poswise_ln/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/past_poswise_ln/gamma:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/ffn/conv1/kernel:0' shape=(768, 3072) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/ffn/conv1/bias:0' shape=(3072,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/ffn/conv2/kernel:0' shape=(3072, 768) dtype=float32_ref>, <tf.Variable 'transformer_decoder/layer_5/ffn/conv2/bias:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/beta:0' shape=(768,) dtype=float32_ref>, <tf.Variable 'transformer_decoder/gamma:0' shape=(768,) dtype=float32_ref>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eho6nZ8n_TVO",
        "colab_type": "code",
        "outputId": "03036628-dd2a-4247-fd86-d820b5143281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tgt_embedding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concat:0' shape=(30522, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "sfDuR-SVkdhF",
        "colab_type": "code",
        "outputId": "fde73a31-d2bf-49e8-d141-714ad0ab8092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#prediction \n",
        "start_tokens = tf.fill([tx.utils.get_batch_size(src_input_ids)],\n",
        "                       bos_token_id)\n",
        "beam_width=4\n",
        "predictions = decoder(\n",
        "    memory=encoder_output,\n",
        "    memory_sequence_length=src_input_length,\n",
        "    decoding_strategy='infer_greedy',\n",
        "    beam_width=beam_width,\n",
        "    length_penalty=1,\n",
        "    #alpha=alpha,\n",
        "    start_tokens=start_tokens,\n",
        "    end_token=eos_token_id,\n",
        "    max_decoding_length=150,\n",
        "    mode=tf.estimator.ModeKeys.PREDICT\n",
        ")\n",
        "\n",
        "\n",
        "print(beam_width)\n",
        "if beam_width <= 1:\n",
        "    inferred_ids = predictions[0].sample_id\n",
        "else:\n",
        "    # Uses the best sample by beam search\n",
        "    inferred_ids = predictions['sample_id'][:, :, 0]\n",
        "    \n",
        "\n",
        "\n",
        "saver = tf.train.Saver(max_to_keep=5)\n",
        "best_results = {'score': 0, 'epoch': -1}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LENv7R8QS7rx",
        "colab_type": "code",
        "outputId": "5fd1d7e4-4177-4c10-e23c-c9af69c967dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "encoder_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'bert/encoder_1/layer_11/ffn/LayerNorm/batchnorm/add_1:0' shape=(?, ?, 768) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "TCmgMIV6kzO4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "def _train_epoch(sess, epoch, step, smry_writer):\n",
        "        \n",
        "            \n",
        "        fetches = {\n",
        "            'step': global_step,\n",
        "            'train_op': train_op,\n",
        "            'smry': summary_merged,\n",
        "            'loss': mle_loss,\n",
        "        }\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "              feed_dict = {\n",
        "                iterator.handle: iterator.get_handle(sess, 'train'),\n",
        "                tx.global_mode(): tf.estimator.ModeKeys.TRAIN,\n",
        "              }\n",
        "              op = sess.run([batch],feed_dict)\n",
        "              feed_dict = {\n",
        "                   src_input_ids:op[0]['src_input_ids'],\n",
        "                   src_segment_ids : op[0]['src_segment_ids'],\n",
        "                   tgt_input_ids:op[0]['tgt_input_ids'],\n",
        "\n",
        "                   labels:op[0]['tgt_labels'],\n",
        "                   learning_rate: utils.get_lr(step, lr),\n",
        "                   tx.global_mode(): tf.estimator.ModeKeys.TRAIN\n",
        "                }\n",
        "\n",
        "\n",
        "              fetches_ = sess.run(fetches, feed_dict=feed_dict)\n",
        "              step, loss = fetches_['step'], fetches_['loss']\n",
        "              if step and step % display_steps == 0:\n",
        "                  with open(os.path.join(r'./gdrive/My Drive/models_log','model12_loss.txt'),'a')as  file_obj:\n",
        "                      print(step,loss,file=file_obj)\n",
        "                      #print(step+\"loss:\"+loss,file=file_obj)\n",
        "                      #print(\"Step:\"+step+\"loss:\"+loss,file=file_obj)\n",
        "                      #print(\"sucess\",file=file_obj)\n",
        "                  logger.info('step: %d, loss: %.4f', step, loss)\n",
        "                  print('step: %d, loss: %.4f' % (step, loss))\n",
        "                  smry_writer.add_summary(fetches_['smry'], global_step=step)\n",
        "\n",
        "              if step and step % 1000 == 0:\n",
        "                  model_path = \"gs://my_bert_summ/models12/model_\"+str(step)+\".ckpt\"\n",
        "                  #logger.info('saving model to %s', model_path)\n",
        "                  print('saving model to %s' % model_path)\n",
        "                  saver.save(sess, model_path)\n",
        "                  _eval_epoch(sess, epoch,step,mode='eval')\n",
        "              #if step and step % eval_steps == 0:\n",
        "              #    _eval_epoch(sess, epoch, mode='eval')\n",
        "            except tf.errors.OutOfRangeError:\n",
        "                break\n",
        "\n",
        "        return step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNEONvrhlDJd",
        "colab_type": "code",
        "outputId": "1db65c01-43bd-4f59-c8a1-19fd524f6558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (0.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xzHdmERjlTCD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "from rouge import Rouge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7NxQ5RCKwaSt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _eval_epoch(sess, epoch, step,mode):\n",
        "        \n",
        "        iterator.initialize_dataset(sess,'eval')\n",
        "        avg = 0\n",
        "\n",
        "        references, hypotheses,my_input,my_try = [], [], [], []\n",
        "        bsize = test_batch_size\n",
        "        fetches= {\n",
        "                'inferred_ids': inferred_ids\n",
        "            }\n",
        "#         fetches2={\n",
        "#             'p':p\n",
        "#         }\n",
        "#         print(\"The mystery\")\n",
        "#         print(p)\n",
        "        bno=0\n",
        "        while (bno<1):\n",
        "            \n",
        "            #print(\"Temp\",temp)\n",
        "            try:\n",
        "              print(\"Batch\",bno)\n",
        "              feed_dict = {\n",
        "              iterator.handle: iterator.get_handle(sess, 'eval'),\n",
        "              tx.global_mode(): tf.estimator.ModeKeys.EVAL,\n",
        "              }\n",
        "              op = sess.run([batch],feed_dict)\n",
        "              #print(\"The twist\")\n",
        "              #print(op[0]['src_input_ids'])\n",
        "              \n",
        "              \n",
        "              feed_dict = {\n",
        "                   src_input_ids:op[0]['src_input_ids'],\n",
        "                   src_segment_ids : op[0]['src_segment_ids'],\n",
        "                   tx.global_mode(): tf.estimator.ModeKeys.EVAL\n",
        "              }\n",
        "              fetches_= sess.run(fetches, feed_dict=feed_dict)\n",
        "\n",
        "              \n",
        "              labels = op[0]['tgt_labels']\n",
        "             \n",
        "              \n",
        "              my_input.extend(m.tolist() for m in op[0]['src_input_ids'] )\n",
        "              hypotheses.extend(h.tolist() for h in fetches_['inferred_ids'])\n",
        "              references.extend(r.tolist() for r in labels)\n",
        "             \n",
        "#               inv_map = {v: k for k, v in tokenizer.vocab.items()}\n",
        "\n",
        "#               for i in hypotheses:\n",
        "#                   for j in i:\n",
        "#                       print(j)\n",
        "#                       if(inv_map[j][0]=='#'):\n",
        "#                         inv_map[j].replace(\" ##\", \"\")\n",
        "#                       #  \" \". Join(inv_map[j]).replace(\" ##\", \"\")\n",
        "#                       else:\n",
        "#                         print(inv_map[j], end=\" \")\n",
        "#                   print(\"\\n\")\n",
        "                 \n",
        "#               for i in references:\n",
        "#                   for j in i:\n",
        "#                       if(inv_map[j][0]=='#'):\n",
        "#                         inv_map[j].replace(\" ##\", \"\")\n",
        "#                       else:\n",
        "#                         print(inv_map[j], end=\" \")\n",
        "#                   print(\"\\n\")    \n",
        "                \n",
        "              hypotheses = utils.list_strip_eos(hypotheses, eos_token_id)\n",
        "              references = utils.list_strip_eos(references, eos_token_id)\n",
        "              references = utils.list_strip_eos(references, 0)\n",
        "              my_input = utils.list_strip_eos(my_input, eos_token_id)\n",
        "                \n",
        "              rouge = Rouge()\n",
        "              \n",
        "              for i in range(1):\n",
        "                  myindex = (4*bno)+i\n",
        " \n",
        "                  hwords = tokenizer.convert_ids_to_tokens(hypotheses[myindex])\n",
        "                  rwords = tokenizer.convert_ids_to_tokens(references[myindex])\n",
        "                  iwords = tokenizer.convert_ids_to_tokens(my_input[myindex])\n",
        "                  hwords = tx.utils.str_join(hwords).replace(\" ##\",\"\")\n",
        "                  rwords = tx.utils.str_join(rwords).replace(\" ##\",\"\")\n",
        "                  #print(len(rwords))\n",
        "                  #rwords = tx.utils.str_join(rwords).replace(\"[PAD]\",\"\")\n",
        "                  #rwords.replace(\"[PAD]\", \"\")\n",
        "                  #print(rwords)\n",
        "                  #print(type(rwords))\n",
        "                  #print(len(rwords))\n",
        "                    \n",
        "#                   iwords = tx.utils.str_join(iwords).replace(\" ##\",\"\")\n",
        "                  rouge = Rouge()\n",
        "                  r = rouge.get_scores(hwords, rwords)\n",
        "                  with open(os.path.join(r'./gdrive/My Drive/models_log','model12_rogue.txt'),'a')as  file_obj:\n",
        "                      print(\"Rogue is:\")\n",
        "                      print(r,file=file_obj)\n",
        "                      print(\"<original>\",file=file_obj)\n",
        "                      print(rwords,file=file_obj)\n",
        "                      print(\"</original>\",file=file_obj)\n",
        "                      print(\"<generated>\",file=file_obj)\n",
        "                      print(hwords,file=file_obj)\n",
        "                      print(\"</generated>\",file=file_obj)\n",
        "                      \n",
        "                      \n",
        "                  print(\"rougue is\")\n",
        "                  print(r)\n",
        "#                   avg = avg+r[0]['rouge-1']['f']\n",
        "#                   print(\"score is\")\n",
        "#                   print(avg)\n",
        "#                  print(\"Original Paragraph\",iwords)\n",
        "#                  print(\"Original\",rwords)\n",
        "#                  print(\"Generated\",hwords)\n",
        "#                  logger2.info(hwords)\n",
        "#              fname = \"./tmp2.eval\"\n",
        "              \n",
        "\n",
        "              \n",
        "                        \n",
        "             \n",
        "              bno = bno+1\n",
        "              \n",
        "            except tf.errors.OutOfRangeError:\n",
        "                break\n",
        "                \n",
        "#         hypotheses = tx.utils.str_join(hypotheses)\n",
        "#         references = tx.utils.str_join(references)\n",
        "#         hyp_fn, ref_fn = tx.utils.write_paired_text(\n",
        "#         hypotheses, references, fname, mode='s')\n",
        "#         rouge = Rouge()\n",
        "#         r = rouge.get_scores(hyp_fn, ref_fn)\n",
        "#         print\n",
        "#         print(\"Rogue\")\n",
        "#         print(str(r))\n",
        "#         eval_bleu = bleu_wrapper(ref_fn, hyp_fn, case_sensitive=True)\n",
        "#         #eval_bleu = bleu_wrapper(ref_fn, ref_fn, case_sensitive=True)\n",
        "#         eval_bleu = 100. * eval_bleu\n",
        "#         print('rogue %.4f' % (r)) \n",
        "#        logger2.info('step:%d ,rogue %.4f',step,r)\n",
        "#         if(step % 50000 == 0):\n",
        "#             logger.info('epoch: %d, eval_bleu %.4f', epoch, eval_bleu)\n",
        "#             print('epoch: %d, eval_bleu %.4f' % (epoch, eval_bleu))\n",
        "\n",
        "#             if eval_bleu > best_results['score']:\n",
        "#                 logger.info('epoch: %d, best bleu: %.4f', epoch, eval_bleu)\n",
        "#                 best_results['score'] = eval_bleu\n",
        "#                 best_results['epoch'] = epoch\n",
        "#                 #model_path = os.path.join(model_dir, 'best-model.ckpt')\n",
        "#                 model_path = \"gs://my_bert_summ/models5/best-model.ckpt\"\n",
        "#                 logger.info('saving model to %s', model_path)\n",
        "#                 print('saving model to %s' % model_path)\n",
        "#                 saver.save(sess, model_path)\n",
        "            \n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        if mode == 'hahaha':\n",
        "            \n",
        "            # Writes results to files to evaluate BLEU\n",
        "            # For 'eval' mode, the BLEU is based on token ids (rather than\n",
        "            # text tokens) and serves only as a surrogate metric to monitor\n",
        "            # the training process\n",
        "            #fname = os.path.join(model_dir, 'tmp.eval')\n",
        "            fname = \"./tmp.eval\"\n",
        "            #fname = \"gs://my_bert_summ/models/tmp.eval\"\n",
        "            hypotheses = tx.utils.str_join(hypotheses)\n",
        "            references = tx.utils.str_join(references)\n",
        "            hyp_fn, ref_fn = tx.utils.write_paired_text(\n",
        "                hypotheses, references, fname, mode='s')\n",
        "            eval_bleu = bleu_wrapper(ref_fn, hyp_fn, case_sensitive=True)\n",
        "            eval_bleu = 100. * eval_bleu\n",
        "            logger.info('epoch: %d, eval_bleu %.4f', epoch, eval_bleu)\n",
        "            print('epoch: %d, eval_bleu %.4f' % (epoch, eval_bleu))\n",
        "\n",
        "            if eval_bleu > best_results['score']:\n",
        "                logger.info('epoch: %d, best bleu: %.4f', epoch, eval_bleu)\n",
        "                best_results['score'] = eval_bleu\n",
        "                best_results['epoch'] = epoch\n",
        "                #model_path = os.path.join(model_dir, 'best-model.ckpt')\n",
        "                model_path = \"gs://my_bert_summ/models10/best-model.ckpt\"\n",
        "                logger.info('saving model to %s', model_path)\n",
        "                print('saving model to %s' % model_path)\n",
        "                saver.save(sess, model_path)\n",
        "               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWIggk34NpLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def infer_single_example(story,actual_summary,tokenizer,sess):\n",
        "      my_example = {\"src_txt\":story,\n",
        "      \"tgt_txt\":actual_summary\n",
        "      }\n",
        "#      for key,val in my_example.items():\n",
        "#          print (key)\n",
        "      print(my_example['src_txt'])\n",
        "      \n",
        "   \n",
        "      \n",
        "      features = convert_single_example(1,my_example,max_seq_length_src,max_seq_length_tgt,tokenizer)\n",
        "#      print(np.array(features.tgt_labels).reshape(1,-1))\n",
        "      feed_dict = {\n",
        "      src_input_ids:np.array(features.src_input_ids).reshape(1,-1),\n",
        "      src_segment_ids:np.array(features.src_segment_ids).reshape(1,-1)\n",
        "      }\n",
        "\n",
        "      references, hypotheses = [], []\n",
        "      fetches = {\n",
        "      'inferred_ids': inferred_ids,\n",
        "      }\n",
        "      fetches_ = sess.run(fetches, feed_dict=feed_dict)\n",
        "      labels = np.array(features.tgt_labels).reshape(1,-1)\n",
        "      hypotheses.extend(h.tolist() for h in fetches_['inferred_ids'])\n",
        "      references.extend(r.tolist() for r in labels)\n",
        "      print(\"Hypotheses is\")\n",
        "      print(hypotheses)\n",
        "      print(\"Reference is\")\n",
        "      print(references)\n",
        "      hypotheses = utils.list_strip_eos(hypotheses, eos_token_id)\n",
        "      references = utils.list_strip_eos(references, eos_token_id)\n",
        "      hwords = tokenizer.convert_ids_to_tokens(hypotheses[0])\n",
        "      rwords = tokenizer.convert_ids_to_tokens(references[0])\n",
        "\n",
        "      hwords = tx.utils.str_join(hwords).replace(\" ##\",\"\")\n",
        "      rwords = tx.utils.str_join(rwords).replace(\" ##\",\"\")\n",
        "      print(\"Original\",rwords)\n",
        "      print(\"Generated\",hwords)\n",
        "      return hwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gt_uH5Zm01Z6",
        "colab_type": "code",
        "outputId": "fd6dfbd3-8209-401c-d538-27a2e61463c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "with tf.Session() as sess:\n",
        "    model_dir = \"gs://my_bert_summ/models10/\"\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
        "    hwords = infer_single_example(story,summary,tokenizer,sess)\n",
        "    print(hwords)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://my_bert_summ/models5/model_114000.ckpt\n",
            "For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.\n",
            "{'src_txt': 'For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.', 'tgt_txt': 'For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.Pope Francis said Sunday that he would hold a meeting of cardinals on February 14 during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world, according to Vatican Radio. New cardinals are always important because they set the tone in the church and also elect the next pope, CNN Senior Vatican Analyst John L. Allen said. They are sometimes referred to as the princes of the Catholic Church. The new cardinals come from countries such as Ethiopia, New Zealand and Myanmar.'}\n",
            "yay\n",
            "Hypotheses is\n",
            "[[1996, 2047, 9310, 2097, 2022, 5361, 2006, 2337, 2004, 12620, 2004, 1996, 2047, 9310, 2004, 12620, 1998, 1996, 2862, 1996, 14655, 2005, 4557, 2004, 12620, 1998, 1996, 3025, 2051, 1999, 4557, 2081, 2285, 2004, 3032, 1996, 2047, 9310, 2081, 2004, 1996, 2047, 9310, 2000, 1996, 2047, 9310, 2027, 2097, 2022]]\n",
            "Reference is\n",
            "[[2005, 1996, 2117, 2051, 2076, 2010, 25097, 1010, 4831, 4557, 2038, 2623, 1037, 2047, 2177, 1997, 8414, 1998, 6507, 2015, 2275, 2000, 2468, 9310, 1011, 1011, 1998, 2027, 2272, 2013, 2035, 2058, 1996, 2088, 1012, 4831, 4557, 2056, 4465, 2008, 2002, 2052, 2907, 1037, 3116, 1997, 9310, 2006, 2337, 2403, 2076, 2029, 1045, 2097, 2171, 2321, 2047, 9310, 2040, 1010, 2746, 2013, 2410, 3032, 2013, 2296, 9983, 1010, 19676, 1996, 27427, 14643, 4747, 12083, 2571, 6971, 2090, 1996, 2277, 1997, 4199, 1998, 1996, 3327, 5231, 2556, 1999, 1996, 2088, 1010, 2429, 2000, 12111, 2557, 1012, 2047, 9310, 2024, 2467, 2590, 2138, 2027, 2275, 1996, 4309, 1999, 1996, 2277, 1998, 2036, 11322, 1996, 2279, 4831, 1010, 13229, 3026, 12111, 12941, 2198, 1048, 1012, 5297, 2056, 1012, 2027, 2024, 2823, 3615, 2000, 2004, 1996, 12000, 1997, 1996, 3234, 2277, 1012, 1996, 2047, 9310, 2272, 2013, 3032, 2107, 2004, 11154, 1010, 2047, 3414, 1998, 12620, 1012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "Original for the second time during his papacy , pope francis has announced a new group of bishops and archbishops set to become cardinals - - and they come from all over the world . pope francis said sunday that he would hold a meeting of cardinals on february 14 during which i will name 15 new cardinals who , coming from 13 countries from every continent , manifest the indissoluble links between the church of rome and the particular churches present in the world , according to vatican radio . new cardinals are always important because they set the tone in the church and also elect the next pope , cnn senior vatican analyst john l . allen said . they are sometimes referred to as the princes of the catholic church . the new cardinals come from countries such as ethiopia , new zealand and myanmar . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Generated the new cardinals will be installed on february as myanmar as the new cardinals as myanmar and the list the haul for francis as myanmar and the previous time in francis made december as countries the new cardinals made as the new cardinals to the new cardinals they will be\n",
            "the new cardinals will be installed on february as myanmar as the new cardinals as myanmar and the list the haul for francis as myanmar and the previous time in francis made december as countries the new cardinals made as the new cardinals to the new cardinals they will be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0dBiU5sLQjjy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary =\"For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.Pope Francis said Sunday that he would hold a meeting of cardinals on February 14 during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world, according to Vatican Radio. New cardinals are always important because they set the tone in the church and also elect the next pope, CNN Senior Vatican Analyst John L. Allen said. They are sometimes referred to as the princes of the Catholic Church. The new cardinals come from countries such as Ethiopia, New Zealand and Myanmar.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXSFcFbL1MzZ",
        "colab_type": "code",
        "outputId": "d8c59838-be46-4517-e662-b1c498538e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "story = str()\n",
        "story = \"For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.Pope Francis said Sunday that he would hold a meeting of cardinals on February 14 during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world, according to Vatican Radio.New cardinals are always important because they set the tone in the church and also elect the next pope, CNN Senior Vatican Analyst John L. Allen said. They are sometimes referred to as the princes of the Catholic Church.The new cardinals come from countries such as Ethiopia, New Zealand and Myanmar.This is a pope who very much wants to reach out to people on the margins, and you clearly see that in this set, Allen said. You're talking about cardinals from typically overlooked places, like Cape Verde, the Pacific island of Tonga, Panama, Thailand, Uruguay.But for the second time since Francis' election, no Americans made the list.Francis pattern is very clear: He wants to go to the geographical peripheries rather than places that are already top-heavy with cardinals, Allen said.Christopher Bellitto, a professor of church history at Kean University in New Jersey, noted that Francis announced his new slate of cardinals on the Catholic Feast of the Epiphany, which commemorates the visit of the Magi to Jesus birthplace in Bethlehem.On feast of three wise men from far away, the Pope choices for cardinal say that every local church deserves a place at the big table.In other words, Francis wants a more decentralized church and wants to hear reform ideas from small communities that sit far from Catholicism power centers, Bellitto said.That does not mean Francis is the first pontiff to appoint cardinals from the developing world, though. Beginning in the 1920s, an increasing number of Latin American churchmen were named cardinals, and in the 1960s, St. John XXIII, whom Francis canonized last year, appointed the first cardinals from Japan, the Philippines and Africa.In addition to the 15 new cardinals Francis named on Sunday, five retired archbishops and bishops will also be honored as cardinals.Last year, Pope Francis appointed 19 new cardinals, including bishops from Haiti and Burkina Faso.CNNs Daniel Burke and Christabelle Fombu contributed to this report.\"\n",
        "print(story)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.Pope Francis said Sunday that he would hold a meeting of cardinals on February 14 during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world, according to Vatican Radio.New cardinals are always important because they set the tone in the church and also elect the next pope, CNN Senior Vatican Analyst John L. Allen said. They are sometimes referred to as the princes of the Catholic Church.The new cardinals come from countries such as Ethiopia, New Zealand and Myanmar.This is a pope who very much wants to reach out to people on the margins, and you clearly see that in this set, Allen said. You're talking about cardinals from typically overlooked places, like Cape Verde, the Pacific island of Tonga, Panama, Thailand, Uruguay.But for the second time since Francis' election, no Americans made the list.Francis pattern is very clear: He wants to go to the geographical peripheries rather than places that are already top-heavy with cardinals, Allen said.Christopher Bellitto, a professor of church history at Kean University in New Jersey, noted that Francis announced his new slate of cardinals on the Catholic Feast of the Epiphany, which commemorates the visit of the Magi to Jesus birthplace in Bethlehem.On feast of three wise men from far away, the Pope choices for cardinal say that every local church deserves a place at the big table.In other words, Francis wants a more decentralized church and wants to hear reform ideas from small communities that sit far from Catholicism power centers, Bellitto said.That does not mean Francis is the first pontiff to appoint cardinals from the developing world, though. Beginning in the 1920s, an increasing number of Latin American churchmen were named cardinals, and in the 1960s, St. John XXIII, whom Francis canonized last year, appointed the first cardinals from Japan, the Philippines and Africa.In addition to the 15 new cardinals Francis named on Sunday, five retired archbishops and bishops will also be honored as cardinals.Last year, Pope Francis appointed 19 new cardinals, including bishops from Haiti and Burkina Faso.CNNs Daniel Burke and Christabelle Fombu contributed to this report.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wb5fCjbYH7RE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "story =\"For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5EipKHS3Q11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary =\"The 15 new cardinals will be installed on February 14.They come from countries such as Myanmar and Tonga.No Americans made the list this time or the previous time in Francis' papacy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GTdXBSJnM8xg",
        "colab_type": "code",
        "outputId": "7d8c6d53-b168-4798-f5bb-f36d29717295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 15 new cardinals will be installed on February 14.They come from countries such as Myanmar and Tonga.No Americans made the list this time or the previous time in Francis' papacy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uEhMk0eF1eO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=os.path.join(bert_pretrain_dir, 'vocab.txt'),\n",
        "      do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWASf9D5SL94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary = \"For the second time during his papacy,Pope Francis has announced a new group of bishops and archbishops set to become cardinals -- and they come from all over the world.Pope Francis said Sunday that he would hold a meeting of cardinals on February 14 during which I will name 15 new Cardinals who, coming from 13 countries from every continent, manifest the indissoluble links between the Church of Rome and the particular Churches present in the world, according to Vatican Radio.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ejs7kqYX3NwB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "with tf.Session() as sess:\n",
        "    model_dir = \"gs://my_bert_summ/models10/\"\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
        "    hwords = infer_single_example(story,summary,tokenizer,sess)\n",
        "    print(hwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cs3wdAKgD-Um",
        "colab_type": "code",
        "outputId": "145fde39-6cae-47d6-ac9a-f80cc375226e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v9b6ghCsnT90",
        "colab_type": "code",
        "outputId": "3a02e9f6-e2fc-4f69-a7ff-076b5a964289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11158
        }
      },
      "cell_type": "code",
      "source": [
        "#tx.utils.maybe_create_dir(model_dir)\n",
        "#logging_file = os.path.join(model_dir, 'logging.txt')\n",
        "model_dir = \"gs://my_bert_summ/models12/\"\n",
        "my_info = \"gs://my_bert_summ/info.txt\"\n",
        "logging_file= \"logging.txt\"\n",
        "logging_file2=\"logging2.txt\"\n",
        "logger2 = utils.get_logger(logging_file2)\n",
        "logger = utils.get_logger(logging_file)\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    smry_writer = tf.summary.FileWriter(model_dir, graph=sess.graph)\n",
        "\n",
        "    if run_mode == 'train_and_evaluate':\n",
        "        logger.info('Begin running with train_and_evaluate mode')\n",
        "\n",
        "        if tf.train.latest_checkpoint(model_dir) is not None:\n",
        "            logger.info('Restore latest checkpoint in %s' % model_dir)\n",
        "            saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
        "        \n",
        "        iterator.initialize_dataset(sess)\n",
        "\n",
        "        step = 5000\n",
        "        for epoch in range(max_train_epoch):\n",
        "          iterator.restart_dataset(sess, 'train')\n",
        "          step = _train_epoch(sess, epoch, step, smry_writer)\n",
        "\n",
        "    elif run_mode == 'test':\n",
        "        \n",
        "        logger.info('Begin running with test mode')\n",
        "\n",
        "        logger.info('Restore latest checkpoint in %s' % model_dir)\n",
        "        saver.restore(sess, tf.train.latest_checkpoint(model_dir))\n",
        "\n",
        "        _eval_epoch(sess, 0,0, mode='eval')\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Unknown mode: {}'.format(run_mode))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from gs://my_bert_summ/models12/model_1000.ckpt\n",
            "step: 1100, loss: 7.2520\n",
            "step: 1200, loss: 7.0326\n",
            "step: 1300, loss: 7.2196\n",
            "step: 1400, loss: 6.8648\n",
            "step: 1500, loss: 7.1534\n",
            "step: 1600, loss: 7.3909\n",
            "step: 1700, loss: 6.8392\n",
            "step: 1800, loss: 7.3834\n",
            "step: 1900, loss: 7.4793\n",
            "step: 2000, loss: 7.3457\n",
            "saving model to gs://my_bert_summ/models12/model_2000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.05128204867850112, 'p': 0.16666666666666666, 'r': 0.030303030303030304}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.031117749564398823, 'p': 0.16666666666666666, 'r': 0.030303030303030304}}]\n",
            "step: 2100, loss: 7.2346\n",
            "step: 2200, loss: 7.8237\n",
            "step: 2300, loss: 7.0058\n",
            "step: 2400, loss: 7.3265\n",
            "step: 2500, loss: 7.1357\n",
            "step: 2600, loss: 6.9093\n",
            "step: 2700, loss: 7.5154\n",
            "step: 2800, loss: 7.1254\n",
            "step: 2900, loss: 7.2457\n",
            "step: 3000, loss: 7.4452\n",
            "saving model to gs://my_bert_summ/models12/model_3000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.04651162433748, 'p': 0.1, 'r': 0.030303030303030304}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.032189945041649654, 'p': 0.1, 'r': 0.030303030303030304}}]\n",
            "step: 3100, loss: 6.7929\n",
            "step: 3200, loss: 7.1926\n",
            "step: 3300, loss: 7.0960\n",
            "step: 3400, loss: 7.1765\n",
            "step: 3500, loss: 7.5125\n",
            "step: 3600, loss: 7.0548\n",
            "step: 3700, loss: 7.1084\n",
            "step: 3800, loss: 7.2714\n",
            "step: 3900, loss: 7.6563\n",
            "step: 4000, loss: 7.4728\n",
            "saving model to gs://my_bert_summ/models12/model_4000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.16666666236979177, 'p': 0.26666666666666666, 'r': 0.12121212121212122}, 'rouge-2': {'f': 0.03278688047299183, 'p': 0.041666666666666664, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.10027472527481891, 'p': 0.2, 'r': 0.09090909090909091}}]\n",
            "step: 4100, loss: 7.3977\n",
            "step: 4200, loss: 7.2885\n",
            "step: 4300, loss: 7.2537\n",
            "step: 4400, loss: 6.5200\n",
            "step: 4500, loss: 6.7991\n",
            "step: 4600, loss: 7.0277\n",
            "step: 4700, loss: 7.2019\n",
            "step: 4800, loss: 6.7976\n",
            "step: 4900, loss: 7.0581\n",
            "step: 5000, loss: 7.5422\n",
            "saving model to gs://my_bert_summ/models12/model_5000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13333332942222234, 'p': 0.25, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.033898300407929405, 'p': 0.045454545454545456, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09820788530476315, 'p': 0.25, 'r': 0.09090909090909091}}]\n",
            "step: 5100, loss: 6.8757\n",
            "step: 5200, loss: 7.5004\n",
            "step: 5300, loss: 6.9072\n",
            "step: 5400, loss: 7.1958\n",
            "step: 5500, loss: 7.0261\n",
            "step: 5600, loss: 7.2413\n",
            "step: 5700, loss: 6.9278\n",
            "step: 5800, loss: 7.2551\n",
            "step: 5900, loss: 7.0295\n",
            "step: 6000, loss: 7.1589\n",
            "saving model to gs://my_bert_summ/models12/model_6000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13636363261363646, 'p': 0.2727272727272727, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.0370370327229086, 'p': 0.058823529411764705, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09740259740269691, 'p': 0.2727272727272727, 'r': 0.09090909090909091}}]\n",
            "step: 6100, loss: 7.2553\n",
            "step: 6200, loss: 7.2455\n",
            "step: 6300, loss: 7.2831\n",
            "step: 6400, loss: 7.4496\n",
            "step: 6500, loss: 7.3434\n",
            "step: 6600, loss: 6.9320\n",
            "step: 6700, loss: 6.9639\n",
            "step: 6800, loss: 7.2516\n",
            "step: 6900, loss: 6.9721\n",
            "step: 7000, loss: 7.0686\n",
            "saving model to gs://my_bert_summ/models12/model_7000.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.12765957028519706, 'p': 0.21428571428571427, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.033898300407929405, 'p': 0.045454545454545456, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09966133243721496, 'p': 0.21428571428571427, 'r': 0.09090909090909091}}]\n",
            "step: 7100, loss: 6.9395\n",
            "step: 7200, loss: 7.1170\n",
            "step: 7300, loss: 7.3397\n",
            "step: 7400, loss: 7.1554\n",
            "step: 7500, loss: 7.2345\n",
            "step: 7600, loss: 7.4958\n",
            "step: 7700, loss: 7.4147\n",
            "step: 7800, loss: 6.7613\n",
            "step: 7900, loss: 7.2777\n",
            "step: 8000, loss: 6.9292\n",
            "saving model to gs://my_bert_summ/models12/model_8000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.17777777386666674, 'p': 0.3333333333333333, 'r': 0.12121212121212122}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.09820788530476315, 'p': 0.25, 'r': 0.09090909090909091}}]\n",
            "step: 8100, loss: 7.1498\n",
            "step: 8200, loss: 7.4105\n",
            "step: 8300, loss: 7.0935\n",
            "step: 8400, loss: 7.2480\n",
            "step: 8500, loss: 7.0860\n",
            "step: 8600, loss: 7.2514\n",
            "step: 8700, loss: 7.3105\n",
            "step: 8800, loss: 6.9168\n",
            "step: 8900, loss: 7.4465\n",
            "step: 9000, loss: 6.9397\n",
            "saving model to gs://my_bert_summ/models12/model_9000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13636363261363646, 'p': 0.2727272727272727, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.03773584484158111, 'p': 0.0625, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09740259740269691, 'p': 0.2727272727272727, 'r': 0.09090909090909091}}]\n",
            "step: 9100, loss: 6.9199\n",
            "step: 9200, loss: 7.1414\n",
            "step: 9300, loss: 6.9881\n",
            "step: 9400, loss: 7.0261\n",
            "step: 9500, loss: 7.7472\n",
            "step: 9600, loss: 6.9142\n",
            "step: 9700, loss: 7.2520\n",
            "step: 9800, loss: 7.2994\n",
            "step: 9900, loss: 7.0464\n",
            "step: 10000, loss: 7.0341\n",
            "saving model to gs://my_bert_summ/models12/model_10000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.09302325224445661, 'p': 0.2, 'r': 0.06060606060606061}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.0643798900832069, 'p': 0.2, 'r': 0.06060606060606061}}]\n",
            "step: 10100, loss: 7.2521\n",
            "step: 10200, loss: 6.7253\n",
            "step: 10300, loss: 7.0406\n",
            "step: 10400, loss: 7.0445\n",
            "step: 10500, loss: 6.7312\n",
            "step: 10600, loss: 7.2056\n",
            "step: 10700, loss: 7.4555\n",
            "step: 10800, loss: 6.6030\n",
            "step: 10900, loss: 6.8926\n",
            "step: 11000, loss: 7.0932\n",
            "saving model to gs://my_bert_summ/models12/model_11000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.09090908715909106, 'p': 0.18181818181818182, 'r': 0.06060606060606061}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.06493506493516442, 'p': 0.18181818181818182, 'r': 0.06060606060606061}}]\n",
            "step: 11100, loss: 6.6517\n",
            "step: 11200, loss: 7.2747\n",
            "step: 11300, loss: 6.9177\n",
            "step: 11400, loss: 6.9397\n",
            "step: 11500, loss: 5.6862\n",
            "step: 11600, loss: 7.2602\n",
            "step: 11700, loss: 6.9791\n",
            "step: 11800, loss: 7.5392\n",
            "step: 11900, loss: 6.7218\n",
            "step: 12000, loss: 7.5920\n",
            "saving model to gs://my_bert_summ/models12/model_12000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.1960784268050751, 'p': 0.2777777777777778, 'r': 0.15151515151515152}, 'rouge-2': {'f': 0.028985502272632652, 'p': 0.03125, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.13531566472747378, 'p': 0.2222222222222222, 'r': 0.12121212121212122}}]\n",
            "step: 12100, loss: 6.9073\n",
            "step: 12200, loss: 7.2754\n",
            "step: 12300, loss: 7.2036\n",
            "step: 12400, loss: 7.2451\n",
            "step: 12500, loss: 6.5834\n",
            "step: 12600, loss: 6.4254\n",
            "step: 12700, loss: 7.1615\n",
            "step: 12800, loss: 7.1875\n",
            "step: 12900, loss: 5.9239\n",
            "step: 13000, loss: 6.6103\n",
            "saving model to gs://my_bert_summ/models12/model_13000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.08333332903645856, 'p': 0.13333333333333333, 'r': 0.06060606060606061}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.06684981684991051, 'p': 0.13333333333333333, 'r': 0.06060606060606061}}]\n",
            "step: 13100, loss: 7.2392\n",
            "step: 13200, loss: 7.0053\n",
            "step: 13300, loss: 6.6291\n",
            "step: 13400, loss: 7.3553\n",
            "step: 13500, loss: 7.2727\n",
            "step: 13600, loss: 6.7046\n",
            "step: 13700, loss: 6.8319\n",
            "step: 13800, loss: 7.3277\n",
            "step: 13900, loss: 7.0379\n",
            "step: 14000, loss: 7.3317\n",
            "saving model to gs://my_bert_summ/models12/model_14000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.17777777386666674, 'p': 0.3333333333333333, 'r': 0.12121212121212122}, 'rouge-2': {'f': 0.035714281230867916, 'p': 0.05263157894736842, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.13094384707298298, 'p': 0.3333333333333333, 'r': 0.12121212121212122}}]\n",
            "step: 14100, loss: 6.9034\n",
            "step: 14200, loss: 6.9748\n",
            "step: 14300, loss: 6.5652\n",
            "step: 14400, loss: 7.1569\n",
            "step: 14500, loss: 7.6899\n",
            "step: 14600, loss: 7.4210\n",
            "step: 14700, loss: 6.9106\n",
            "step: 14800, loss: 7.2791\n",
            "step: 14900, loss: 7.2779\n",
            "step: 15000, loss: 6.6987\n",
            "saving model to gs://my_bert_summ/models12/model_15000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13636363261363646, 'p': 0.2727272727272727, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.06493506493516442, 'p': 0.18181818181818182, 'r': 0.06060606060606061}}]\n",
            "step: 15100, loss: 6.6459\n",
            "step: 15200, loss: 6.8776\n",
            "step: 15300, loss: 6.5207\n",
            "step: 15400, loss: 7.2415\n",
            "step: 15500, loss: 6.9493\n",
            "step: 15600, loss: 6.8043\n",
            "step: 15700, loss: 6.7317\n",
            "step: 15800, loss: 7.3044\n",
            "step: 15900, loss: 7.1659\n",
            "step: 16000, loss: 6.7036\n",
            "saving model to gs://my_bert_summ/models12/model_16000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.27450979935409464, 'p': 0.3888888888888889, 'r': 0.21212121212121213}, 'rouge-2': {'f': 0.030769225865089542, 'p': 0.03571428571428571, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.16914458090933115, 'p': 0.2777777777777778, 'r': 0.15151515151515152}}]\n",
            "step: 16100, loss: 7.1332\n",
            "step: 16200, loss: 7.1295\n",
            "step: 16300, loss: 6.5190\n",
            "step: 16400, loss: 7.1645\n",
            "step: 16500, loss: 6.7048\n",
            "step: 16600, loss: 7.2461\n",
            "step: 16700, loss: 7.1063\n",
            "step: 16800, loss: 6.2872\n",
            "step: 16900, loss: 6.6706\n",
            "step: 17000, loss: 6.7528\n",
            "saving model to gs://my_bert_summ/models12/model_17000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13636363261363646, 'p': 0.2727272727272727, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.03773584484158111, 'p': 0.0625, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09740259740269691, 'p': 0.2727272727272727, 'r': 0.09090909090909091}}]\n",
            "step: 17100, loss: 6.8869\n",
            "step: 17200, loss: 7.0510\n",
            "step: 17300, loss: 6.5332\n",
            "step: 17400, loss: 7.0254\n",
            "step: 17500, loss: 7.1793\n",
            "step: 17600, loss: 6.5210\n",
            "step: 17700, loss: 6.9703\n",
            "step: 17800, loss: 6.4669\n",
            "step: 17900, loss: 7.0925\n",
            "step: 18000, loss: 7.2883\n",
            "saving model to gs://my_bert_summ/models12/model_18000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13043477855387536, 'p': 0.23076923076923078, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.034482754001189685, 'p': 0.047619047619047616, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09896680127980226, 'p': 0.23076923076923078, 'r': 0.09090909090909091}}]\n",
            "step: 18100, loss: 6.6010\n",
            "step: 18200, loss: 7.0567\n",
            "step: 18300, loss: 7.1212\n",
            "step: 18400, loss: 6.0395\n",
            "step: 18500, loss: 7.2504\n",
            "step: 18600, loss: 6.9978\n",
            "step: 18700, loss: 7.1512\n",
            "step: 18800, loss: 6.9986\n",
            "step: 18900, loss: 5.8918\n",
            "step: 19000, loss: 6.9798\n",
            "saving model to gs://my_bert_summ/models12/model_19000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.2040816282548939, 'p': 0.3125, 'r': 0.15151515151515152}, 'rouge-2': {'f': 0.03225805970343464, 'p': 0.04, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.10079184672653244, 'p': 0.1875, 'r': 0.09090909090909091}}]\n",
            "step: 19100, loss: 7.1254\n",
            "step: 19200, loss: 6.8880\n",
            "step: 19300, loss: 7.1417\n",
            "step: 19400, loss: 7.0222\n",
            "step: 19500, loss: 7.0581\n",
            "step: 19600, loss: 7.4503\n",
            "step: 19700, loss: 6.8432\n",
            "step: 19800, loss: 6.8739\n",
            "step: 19900, loss: 6.2794\n",
            "step: 20000, loss: 6.9675\n",
            "saving model to gs://my_bert_summ/models12/model_20000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13333332942222234, 'p': 0.25, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.035714281230867916, 'p': 0.05263157894736842, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09820788530476315, 'p': 0.25, 'r': 0.09090909090909091}}]\n",
            "step: 20100, loss: 7.0399\n",
            "step: 20200, loss: 7.3203\n",
            "step: 20300, loss: 7.5553\n",
            "step: 20400, loss: 6.9313\n",
            "step: 20500, loss: 7.2887\n",
            "step: 20600, loss: 7.1748\n",
            "step: 20700, loss: 7.2271\n",
            "step: 20800, loss: 6.8739\n",
            "step: 20900, loss: 6.4640\n",
            "step: 21000, loss: 6.7204\n",
            "saving model to gs://my_bert_summ/models12/model_21000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.16666666236979177, 'p': 0.26666666666666666, 'r': 0.12121212121212122}, 'rouge-2': {'f': 0.033898300407929405, 'p': 0.045454545454545456, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.10027472527481891, 'p': 0.2, 'r': 0.09090909090909091}}]\n",
            "step: 21100, loss: 6.6567\n",
            "step: 21200, loss: 6.8130\n",
            "step: 21300, loss: 7.2376\n",
            "step: 21400, loss: 7.2200\n",
            "step: 21500, loss: 7.6234\n",
            "step: 21600, loss: 6.8156\n",
            "step: 21700, loss: 6.7394\n",
            "step: 21800, loss: 6.8879\n",
            "step: 21900, loss: 6.9351\n",
            "step: 22000, loss: 7.3644\n",
            "saving model to gs://my_bert_summ/models12/model_22000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.1395348801514333, 'p': 0.3, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.038461534356509314, 'p': 0.06666666666666667, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09656983512476416, 'p': 0.3, 'r': 0.09090909090909091}}]\n",
            "step: 22100, loss: 7.0706\n",
            "step: 22200, loss: 6.4104\n",
            "step: 22300, loss: 7.1136\n",
            "step: 22400, loss: 6.8626\n",
            "step: 22500, loss: 6.9712\n",
            "step: 22600, loss: 6.8596\n",
            "step: 22700, loss: 7.1610\n",
            "step: 22800, loss: 6.9323\n",
            "step: 22900, loss: 7.0558\n",
            "step: 23000, loss: 7.0638\n",
            "saving model to gs://my_bert_summ/models12/model_23000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13636363261363646, 'p': 0.2727272727272727, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.03773584484158111, 'p': 0.0625, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09740259740269691, 'p': 0.2727272727272727, 'r': 0.09090909090909091}}]\n",
            "step: 23100, loss: 6.7084\n",
            "step: 23200, loss: 7.0136\n",
            "step: 23300, loss: 6.4561\n",
            "step: 23400, loss: 6.6879\n",
            "step: 23500, loss: 6.5299\n",
            "step: 23600, loss: 6.6009\n",
            "step: 23700, loss: 6.8837\n",
            "step: 23800, loss: 7.1891\n",
            "step: 23900, loss: 7.0805\n",
            "step: 24000, loss: 6.5695\n",
            "saving model to gs://my_bert_summ/models12/model_24000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.09302325224445661, 'p': 0.2, 'r': 0.06060606060606061}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.0643798900832069, 'p': 0.2, 'r': 0.06060606060606061}}]\n",
            "step: 24100, loss: 7.1398\n",
            "step: 24200, loss: 6.7431\n",
            "step: 24300, loss: 7.3946\n",
            "step: 24400, loss: 6.4599\n",
            "step: 24500, loss: 7.0313\n",
            "step: 24600, loss: 6.6617\n",
            "step: 24700, loss: 7.1322\n",
            "step: 24800, loss: 6.8808\n",
            "step: 24900, loss: 7.0476\n",
            "step: 25000, loss: 6.7584\n",
            "saving model to gs://my_bert_summ/models12/model_25000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.21276595326392037, 'p': 0.35714285714285715, 'r': 0.15151515151515152}, 'rouge-2': {'f': 0.033333328605556226, 'p': 0.043478260869565216, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.13288177658291955, 'p': 0.2857142857142857, 'r': 0.12121212121212122}}]\n",
            "step: 25100, loss: 7.4552\n",
            "step: 25200, loss: 6.8673\n",
            "step: 25300, loss: 7.0753\n",
            "step: 25400, loss: 6.5800\n",
            "step: 25500, loss: 6.9804\n",
            "step: 25600, loss: 7.1058\n",
            "step: 25700, loss: 7.0391\n",
            "step: 25800, loss: 7.0492\n",
            "step: 25900, loss: 7.1467\n",
            "step: 26000, loss: 6.8795\n",
            "saving model to gs://my_bert_summ/models12/model_26000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.12244897519366944, 'p': 0.1875, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.06719456448438219, 'p': 0.125, 'r': 0.06060606060606061}}]\n",
            "step: 26100, loss: 6.5968\n",
            "step: 26200, loss: 7.2182\n",
            "step: 26300, loss: 7.0080\n",
            "step: 26400, loss: 6.9791\n",
            "step: 26500, loss: 6.8515\n",
            "step: 26600, loss: 6.6832\n",
            "step: 26700, loss: 6.7359\n",
            "step: 26800, loss: 5.8431\n",
            "step: 26900, loss: 6.6754\n",
            "step: 27000, loss: 6.6247\n",
            "saving model to gs://my_bert_summ/models12/model_27000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.17777777386666674, 'p': 0.3333333333333333, 'r': 0.12121212121212122}, 'rouge-2': {'f': 0.0370370327229086, 'p': 0.058823529411764705, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.13094384707298298, 'p': 0.3333333333333333, 'r': 0.12121212121212122}}]\n",
            "step: 27100, loss: 6.8353\n",
            "step: 27200, loss: 6.6875\n",
            "step: 27300, loss: 7.2014\n",
            "step: 27400, loss: 7.1275\n",
            "step: 27500, loss: 6.5817\n",
            "step: 27600, loss: 6.8252\n",
            "step: 27700, loss: 6.8671\n",
            "step: 27800, loss: 6.5443\n",
            "step: 27900, loss: 6.8306\n",
            "step: 28000, loss: 6.9142\n",
            "saving model to gs://my_bert_summ/models12/model_28000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.21276595326392037, 'p': 0.35714285714285715, 'r': 0.15151515151515152}, 'rouge-2': {'f': 0.033333328605556226, 'p': 0.043478260869565216, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.13288177658291955, 'p': 0.2857142857142857, 'r': 0.12121212121212122}}]\n",
            "step: 28100, loss: 6.5725\n",
            "step: 28200, loss: 7.2159\n",
            "step: 28300, loss: 6.6242\n",
            "step: 28400, loss: 6.7224\n",
            "step: 28500, loss: 7.1074\n",
            "step: 28600, loss: 7.3974\n",
            "step: 28700, loss: 6.5995\n",
            "step: 28800, loss: 7.1257\n",
            "step: 28900, loss: 7.1652\n",
            "step: 29000, loss: 6.9283\n",
            "saving model to gs://my_bert_summ/models12/model_29000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.16666666236979177, 'p': 0.26666666666666666, 'r': 0.12121212121212122}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.10027472527481891, 'p': 0.2, 'r': 0.09090909090909091}}]\n",
            "step: 29100, loss: 6.6562\n",
            "step: 29200, loss: 6.8622\n",
            "step: 29300, loss: 6.5174\n",
            "step: 29400, loss: 6.6660\n",
            "step: 29500, loss: 6.6961\n",
            "step: 29600, loss: 6.8224\n",
            "step: 29700, loss: 6.1849\n",
            "step: 29800, loss: 6.8241\n",
            "step: 29900, loss: 6.1641\n",
            "step: 30000, loss: 6.8416\n",
            "saving model to gs://my_bert_summ/models12/model_30000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.13043477855387536, 'p': 0.23076923076923078, 'r': 0.09090909090909091}, 'rouge-2': {'f': 0.03508771474299844, 'p': 0.05, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.09896680127980226, 'p': 0.23076923076923078, 'r': 0.09090909090909091}}]\n",
            "step: 30100, loss: 7.1518\n",
            "step: 30200, loss: 6.3288\n",
            "step: 30300, loss: 7.0745\n",
            "step: 30400, loss: 6.4863\n",
            "step: 30500, loss: 6.5133\n",
            "step: 30600, loss: 6.9481\n",
            "step: 30700, loss: 6.5456\n",
            "step: 30800, loss: 7.0631\n",
            "step: 30900, loss: 6.9982\n",
            "step: 31000, loss: 7.2497\n",
            "saving model to gs://my_bert_summ/models12/model_31000.ckpt\n",
            "Batch 0\n",
            "234\n",
            "monsignor william lynn must remain in jail for now a judge rules lynns defense attorneys had filed a motion to release the 61yearold on house arrest a judge has delayed the decision on house arrest another hearing scheduled for july 5\n",
            "<class 'str'>\n",
            "234\n",
            "Rogue is:\n",
            "rougue is\n",
            "[{'rouge-1': {'f': 0.24489795478550605, 'p': 0.375, 'r': 0.18181818181818182}, 'rouge-2': {'f': 0.030769225865089542, 'p': 0.03571428571428571, 'r': 0.02702702702702703}, 'rouge-l': {'f': 0.16798641121083288, 'p': 0.3125, 'r': 0.15151515151515152}}]\n",
            "step: 31100, loss: 6.8422\n",
            "step: 31200, loss: 7.0435\n",
            "step: 31300, loss: 6.6813\n",
            "step: 31400, loss: 6.5573\n",
            "step: 31500, loss: 6.7275\n",
            "step: 31600, loss: 7.1739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-436081d0a371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_train_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m           \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmry_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrun_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e462c7fe4a78>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(sess, epoch, step, smry_writer)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m               \u001b[0mfetches_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m               \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetches_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "za3RDatov_v0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e0e37d0-4e55-41c8-b73b-ef94f24f07b3"
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "4Tkb1PIBcuIj",
        "colab_type": "code",
        "outputId": "a7b2a9d7-4458-453f-e78b-d315ef71d8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "orig_tokens = [\"John\", \"Johanson\", \"'s\",  \"house\"]\n",
        "labels      = [\"NNP\",  \"NNP\",      \"POS\", \"NN\"]\n",
        "\n",
        "### Output\n",
        "bert_tokens = []\n",
        "\n",
        "# Token map will be an int -> int mapping between the `orig_tokens` index and\n",
        "# the `bert_tokens` index.\n",
        "orig_to_tok_map = []\n",
        "\n",
        "#tokenizer = tokenization.FullTokenizer(\n",
        "#    vocab_file=vocab_file, do_lower_case=True)\n",
        "\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "        vocab_file=os.path.join(bert_pretrain_dir, 'vocab.txt'),\n",
        "        do_lower_case=True)\n",
        "\n",
        "bert_tokens.append(\"[CLS]\")\n",
        "for orig_token in orig_tokens:\n",
        "  orig_to_tok_map.append(len(bert_tokens))\n",
        "  bert_tokens.extend(tokenizer.tokenize(orig_token))\n",
        "bert_tokens.append(\"[SEP]\")\n",
        "\n",
        "print(bert_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'john', 'johan', '##son', \"'\", 's', 'house', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4vjgVCKKFWBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(tokenizer.vocab.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L35eRRNKSoOV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inv_map = {v: k for k, v in tokenizer.vocab.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TML9jVailhOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc9a38a2-d9a7-4b0b-a489-b18b9abbefd5"
      },
      "cell_type": "code",
      "source": [
        "print(inv_map[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzxgYc8Pos2i",
        "colab_type": "code",
        "outputId": "767f2eb9-48f4-47c8-a944-712cc51b8e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens([102])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}